// æµ‹è¯•å±å¹• - éªŒè¯æ‘„åƒå¤´å’Œ MediaPipe é›†æˆ
import { useEffect, useRef, useState, useCallback } from 'react';
import { useCamera } from '../hooks/useCamera';
import { useMediaPipe } from '../hooks/useMediaPipe';
import { DetectionResult } from '../types';

interface DetectionStats {
  faceDetected: boolean;
  handDetected: boolean;
  jawOpen: number;
  fps: number;
  videoWidth: number;
  videoHeight: number;
}

export const TestScreen: React.FC = () => {
  const { videoRef, isReady, error: cameraError, startCamera, stopCamera } =
    useCamera();

  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [detectionStats, setDetectionStats] = useState<DetectionStats>({
    faceDetected: false,
    handDetected: false,
    jawOpen: 0,
    fps: 0,
    videoWidth: 640,
    videoHeight: 480
  });
  const lastTimeRef = useRef<number>(0);
  const frameCountRef = useRef<number>(0);

  // å®šä¹‰æ£€æµ‹å¤„ç†å‡½æ•°
  const handleDetection = useCallback((result: DetectionResult) => {
    frameCountRef.current++;

    const now = performance.now();
    if (now - lastTimeRef.current >= 1000) {
      const fps = frameCountRef.current;
      frameCountRef.current = 0;
      lastTimeRef.current = now;

      setDetectionStats(prev => ({
        ...prev,
        fps
      }));
    }

    const faceDetected = result.faceResult.landmarks !== null;
    const handDetected = result.handResult.landmarks !== null;
    const jawOpen = result.faceResult.blendshapes?.get('jawOpen') ?? 0;

    // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    setDetectionStats(prev => ({
      ...prev,
      faceDetected,
      handDetected,
      jawOpen,
      videoWidth: videoRef.current?.videoWidth ?? 640,
      videoHeight: videoRef.current?.videoHeight ?? 480
    }));

    // ç»˜åˆ¶è§†é¢‘å’Œå…³é”®ç‚¹
    if (canvasRef.current && videoRef.current) {
      const ctx = canvasRef.current.getContext('2d');
      if (!ctx) return;

      const video = videoRef.current;
      const canvas = canvasRef.current;

      // è°ƒè¯•ï¼šæ£€æŸ¥ video å…ƒç´ çŠ¶æ€
      if (frameCountRef.current === 1) {
        console.log('[TestScreen] Video å…ƒç´ çŠ¶æ€:', {
          videoWidth: video.videoWidth,
          videoHeight: video.videoHeight,
          readyState: video.readyState,
          paused: video.paused,
          srcObject: !!video.srcObject,
          networkState: video.networkState
        });
      }

      // åŒæ­¥ canvas å¤§å°ä¸ video
      if (video.videoWidth > 0 && video.videoHeight > 0) {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        // æ¸…ç©ºç”»å¸ƒ
        ctx.fillStyle = 'black';
        ctx.fillRect(0, 0, canvas.width, canvas.height);

        // ç»˜åˆ¶è§†é¢‘å¸§
        try {
          ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        } catch (error) {
          console.error('[TestScreen] ç»˜åˆ¶è§†é¢‘å¤±è´¥:', error);
          // ç»§ç»­ç»˜åˆ¶è°ƒè¯•ä¿¡æ¯ï¼Œå³ä½¿ç»˜åˆ¶å¤±è´¥
        }

        // ç»˜åˆ¶äººè„¸å…³é”®ç‚¹
        if (faceDetected && result.faceResult.landmarks) {
          ctx.fillStyle = 'rgba(0, 255, 0, 0.7)';
          ctx.strokeStyle = 'rgba(0, 255, 0, 0.5)';
          ctx.lineWidth = 1;

          result.faceResult.landmarks.forEach((landmark, idx) => {
            const x = landmark.x * canvas.width;
            const y = landmark.y * canvas.height;
            ctx.beginPath();
            ctx.arc(x, y, 2, 0, 2 * Math.PI);
            ctx.fill();

            // æ¯10ä¸ªç‚¹è¿ä¸€æ¡çº¿ï¼Œå½¢æˆç½‘æ ¼æ•ˆæœ
            if (idx > 0 && idx % 10 === 0) {
              const prevLandmark = result.faceResult.landmarks![idx - 1];
              const px = prevLandmark.x * canvas.width;
              const py = prevLandmark.y * canvas.height;
              ctx.beginPath();
              ctx.moveTo(px, py);
              ctx.lineTo(x, y);
              ctx.stroke();
            }
          });
        }

        // ç»˜åˆ¶æ‰‹éƒ¨å…³é”®ç‚¹
        if (handDetected && result.handResult.landmarks) {
          ctx.fillStyle = 'rgba(255, 0, 0, 0.7)';
          ctx.strokeStyle = 'rgba(255, 0, 0, 0.5)';
          ctx.lineWidth = 2;

          result.handResult.landmarks.forEach((landmark, idx) => {
            const x = landmark.x * canvas.width;
            const y = landmark.y * canvas.height;
            ctx.beginPath();
            ctx.arc(x, y, 4, 0, 2 * Math.PI);
            ctx.fill();

            // è¿æ¥ç›¸é‚»å…³é”®ç‚¹ï¼ˆæ‰‹æŒ‡ï¼‰
            if (
              result.handResult.landmarks &&
              ((idx > 0 && idx % 4 === 0) || // æ‰‹æŒ‡å…³èŠ‚è¿æ¥
                idx === 9 ||
                idx === 13 ||
                idx === 17)
            ) {
              const prevIdx = idx - 1;
              if (
                prevIdx >= 0 &&
                prevIdx < result.handResult.landmarks.length
              ) {
                const prevLandmark = result.handResult.landmarks[prevIdx];
                const px = prevLandmark.x * canvas.width;
                const py = prevLandmark.y * canvas.height;
                ctx.beginPath();
                ctx.moveTo(px, py);
                ctx.lineTo(x, y);
                ctx.stroke();
              }
            }
          });
        }

        // ç»˜åˆ¶æ–‡æœ¬ä¿¡æ¯
        ctx.fillStyle = 'rgba(0, 0, 0, 0.6)';
        ctx.fillRect(10, 10, 250, 100);

        ctx.fillStyle = '#0f0';
        ctx.font = 'bold 14px monospace';
        ctx.fillText(`FPS: ${detectionStats.fps}`, 20, 30);
        ctx.fillText(`Face: ${faceDetected ? 'âœ“' : 'âœ—'}`, 20, 50);
        ctx.fillText(`Hand: ${handDetected ? 'âœ“' : 'âœ—'}`, 20, 70);
        ctx.fillText(`Jaw Open: ${jawOpen.toFixed(2)}`, 20, 90);
      }
    }
  }, [videoRef, detectionStats.fps]);

  // ä½¿ç”¨ MediaPipe
  const { isInitialized, error: mediaError, startDetection, stopDetection } =
    useMediaPipe({
      videoRef,
      onDetection: handleDetection
    });

  // å¤„ç†å¯åŠ¨
  useEffect(() => {
    if (isReady) {
      console.log('[TestScreen] æ‘„åƒå¤´å·²å‡†å¤‡å¥½ï¼Œå¯åŠ¨æ£€æµ‹');
      startDetection();
      return () => {
        stopDetection();
      };
    }
  }, [isReady, startDetection, stopDetection]);

  const handleStartClick = async () => {
    console.log('[TestScreen] ç‚¹å‡»å¯åŠ¨æ‘„åƒå¤´');
    await startCamera();
  };

  const handleStopClick = () => {
    console.log('[TestScreen] ç‚¹å‡»åœæ­¢');
    stopDetection();
    stopCamera();
  };

  return (
    <div
      style={{
        display: 'flex',
        flexDirection: 'column',
        alignItems: 'center',
        justifyContent: 'center',
        minHeight: '100vh',
        backgroundColor: '#1a1a1a',
        color: '#fff',
        fontFamily: 'monospace',
        padding: '20px',
        gap: '20px'
      }}
    >
      <h1>ğŸ® åˆ·ç‰™æ¸¸æˆ - åŠŸèƒ½æµ‹è¯•</h1>

      {/* é”™è¯¯æ˜¾ç¤º */}
      {(cameraError || mediaError) && (
        <div
          style={{
            backgroundColor: '#ff4444',
            padding: '15px',
            borderRadius: '5px',
            maxWidth: '600px',
            textAlign: 'center'
          }}
        >
          <p>
            <strong>âŒ é”™è¯¯:</strong> {cameraError || mediaError}
          </p>
        </div>
      )}

      {/* æ§åˆ¶æŒ‰é’® */}
      <div style={{ display: 'flex', gap: '10px' }}>
        <button
          onClick={handleStartClick}
          disabled={isReady}
          style={{
            padding: '12px 24px',
            fontSize: '16px',
            cursor: isReady ? 'not-allowed' : 'pointer',
            opacity: isReady ? 0.5 : 1,
            backgroundColor: isReady ? '#666' : '#0f0',
            color: '#000',
            border: 'none',
            borderRadius: '5px',
            fontWeight: 'bold'
          }}
        >
          å¯åŠ¨æ‘„åƒå¤´
        </button>
        <button
          onClick={handleStopClick}
          disabled={!isReady}
          style={{
            padding: '12px 24px',
            fontSize: '16px',
            cursor: !isReady ? 'not-allowed' : 'pointer',
            opacity: !isReady ? 0.5 : 1,
            backgroundColor: !isReady ? '#666' : '#f00',
            color: '#fff',
            border: 'none',
            borderRadius: '5px',
            fontWeight: 'bold'
          }}
        >
          åœæ­¢
        </button>
      </div>

      {/* çŠ¶æ€ä¿¡æ¯ */}
      <div
        style={{
          padding: '15px',
          backgroundColor: '#333',
          borderRadius: '5px',
          textAlign: 'center'
        }}
      >
        <p>æ‘„åƒå¤´: {isReady ? 'âœ“ å·²å¯åŠ¨' : 'âœ— æœªå¯åŠ¨'}</p>
        <p>MediaPipe: {isInitialized ? 'âœ“ å·²åˆå§‹åŒ–' : 'â³ åˆå§‹åŒ–ä¸­...'}</p>
        <p>äººè„¸æ£€æµ‹: {detectionStats.faceDetected ? 'âœ“ æ˜¯' : 'âœ— å¦'}</p>
        <p>æ‰‹éƒ¨æ£€æµ‹: {detectionStats.handDetected ? 'âœ“ æ˜¯' : 'âœ— å¦'}</p>
        <p>å¼ å˜´åˆ†æ•°: {detectionStats.jawOpen.toFixed(2)}</p>
        <p>FPS: {detectionStats.fps}</p>
      </div>

      {/* è§†é¢‘å’Œ Canvas */}
      <div style={{ position: 'relative', width: '100%', maxWidth: '640px' }}>
        <video
          ref={videoRef}
          autoPlay
          muted
          playsInline
          style={{
            position: 'absolute',
            width: '100%',
            height: '100%',
            opacity: 0,
            pointerEvents: 'none',
            zIndex: -1
          }}
        />
        <canvas
          ref={canvasRef}
          style={{
            width: '100%',
            height: 'auto',
            border: '3px solid #0f0',
            borderRadius: '5px',
            backgroundColor: '#000',
            display: 'block'
          }}
        />
      </div>

      <div style={{ fontSize: '12px', color: '#999', textAlign: 'center' }}>
        <p>ğŸŸ¢ ç»¿è‰²ç‚¹: äººè„¸å…³é”®ç‚¹ (468ä¸ª)</p>
        <p>ğŸ”´ çº¢è‰²ç‚¹: æ‰‹éƒ¨å…³é”®ç‚¹ (21ä¸ª)</p>
      </div>
    </div>
  );
};
